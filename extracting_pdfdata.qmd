---
title: "federal_text_retrieval"
format: html
editor: visual
---

## LOADING LIBRARIES

```{r}
install.packages("pdftools")
install.packages("tidyverse")
library(pdftools)
library(tidyverse)
library(lubridate)
```

```{r}
# Set the path to the folder containing the PDFs
folder_path <- "C:/Users/admin/Documents/SentimentAnalysis/fed_press_releases"

# List all PDF files in the folder
pdf_files <- list.files(path = folder_path, pattern = "\\.pdf$", full.names = TRUE)
```

Initiate a list to store all reports in dataframes

```{r}
temp_dfs <- list()
```

```{r}
for (file_path in pdf_files)
{
  # Extract text from the pdf
  pdf_text <- pdf_text(file_path)
  # Insert text into a df temporarily, R splits data by pages into indiviual rows automatically
  temp_df <- data.frame(reports = pdf_text)
  # Combine all page data into 1 string 
  combined_string <- paste(temp_df$reports, collapse = " ")
  
  # Extract date from filename
  date <- gsub(".*?(\\d{8}).*|.*?(\\d{8})[^0-9]", "\\1\\2", file_path)
  date <- as.Date(date, format = "%Y%m%d")
  # Create dataframe and append it to the list
  temp_df <- data.frame(report = combined_string, date= date)
  temp_dfs[[length(temp_dfs) + 1]] <- temp_df
  }
```

Combine all dataframes into 1 single dataframe

```{r}
reports_df <- do.call(rbind, temp_dfs)
```

Write to csv (excel does not render data properly, to check the final df, open it in R-Studio itself)

```{r}
write.csv(reports_df,"reports.csv")
```

```{r}
reports_df[1,1]
```
